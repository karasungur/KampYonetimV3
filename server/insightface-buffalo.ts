import * as ort from 'onnxruntime-node';
import sharp from 'sharp';
import * as fs from 'fs';
import * as path from 'path';

export class InsightFaceBuffaloL {
  private session: ort.InferenceSession | null = null;
  private modelPath: string;

  constructor() {
    this.modelPath = path.join(process.cwd(), 'models', 'buffalo_l.onnx');
  }

  async loadModel(): Promise<void> {
    try {
      console.log('ğŸ¦¬ InsightFace Buffalo_L model yÃ¼kleniyor...');
      
      // Model dosyasÄ±nÄ±n var olup olmadÄ±ÄŸÄ±nÄ± kontrol et
      if (!fs.existsSync(this.modelPath)) {
        console.log('âš ï¸ Buffalo_L model dosyasÄ± bulunamadÄ±, simÃ¼le edilmiÅŸ embedding kullanÄ±lacak');
        throw new Error(`Model dosyasÄ± bulunamadÄ±: ${this.modelPath}`);
      }

      console.log(`ğŸ“ Model dosyasÄ± bulundu: ${this.modelPath}`);
      console.log(`ğŸ“Š Model boyutu: ${(fs.statSync(this.modelPath).size / 1024 / 1024).toFixed(2)} MB`);

      // ONNX session oluÅŸtur
      this.session = await ort.InferenceSession.create(this.modelPath, {
        executionProviders: ['cpu'], // CPU provider kullan
        logSeverityLevel: 3, // ERROR level
      });

      console.log('âœ… InsightFace Buffalo_L model baÅŸarÄ±yla yÃ¼klendi');
      console.log('ğŸ“‹ Model input shapes:', this.session.inputNames.map(name => {
        const metadata = this.session?.inputMetadata[name];
        return `${name}: ${metadata?.dims?.join('x') || 'unknown'}`;
      }));
      
    } catch (error) {
      console.error('âŒ InsightFace Buffalo_L model yÃ¼kleme hatasÄ±:', error);
      throw error;
    }
  }

  async preprocessImage(imageBuffer: Buffer): Promise<ort.Tensor> {
    try {
      console.log('ğŸ–¼ï¸ GÃ¶rÃ¼ntÃ¼ Ã¶n iÅŸleme baÅŸlÄ±yor...');
      
      // Sharp ile gÃ¶rÃ¼ntÃ¼yÃ¼ iÅŸle  
      const processedImage = await sharp(imageBuffer)
        .resize(112, 112) // InsightFace standart boyutu
        .removeAlpha() // Alpha kanalÄ±nÄ± kaldÄ±r
        .raw()
        .toBuffer();

      console.log('ğŸ“ GÃ¶rÃ¼ntÃ¼ boyutu: 112x112');

      // RGB deÄŸerlerini normalize et [0-255] -> [-1, 1]
      const float32Data = new Float32Array(3 * 112 * 112);
      for (let i = 0; i < processedImage.length; i += 3) {
        // RGB -> CHW format (Channel-Height-Width)
        const r = processedImage[i] / 127.5 - 1.0;
        const g = processedImage[i + 1] / 127.5 - 1.0;
        const b = processedImage[i + 2] / 127.5 - 1.0;

        const pixelIndex = Math.floor(i / 3);
        const h = Math.floor(pixelIndex / 112);
        const w = pixelIndex % 112;

        // CHW format: [C, H, W]
        float32Data[0 * 112 * 112 + h * 112 + w] = r; // R channel
        float32Data[1 * 112 * 112 + h * 112 + w] = g; // G channel
        float32Data[2 * 112 * 112 + h * 112 + w] = b; // B channel
      }

      // ONNX Tensor oluÅŸtur
      const tensor = new ort.Tensor('float32', float32Data, [1, 3, 112, 112]);
      console.log('âœ… Tensor oluÅŸturuldu:', tensor.dims);
      
      return tensor;
    } catch (error) {
      console.error('âŒ GÃ¶rÃ¼ntÃ¼ Ã¶n iÅŸleme hatasÄ±:', error);
      throw error;
    }
  }

  async extractEmbedding(imageBuffer: Buffer): Promise<number[]> {
    try {
      if (!this.session) {
        await this.loadModel();
      }

      console.log('ğŸ” Embedding Ã§Ä±karma baÅŸlÄ±yor...');
      
      // GÃ¶rÃ¼ntÃ¼yÃ¼ Ã¶n iÅŸle
      const inputTensor = await this.preprocessImage(imageBuffer);

      // Model inference
      const feeds: Record<string, ort.Tensor> = {};
      feeds[this.session!.inputNames[0]] = inputTensor;

      console.log('ğŸ§  Model inference Ã§alÄ±ÅŸÄ±yor...');
      const results = await this.session!.run(feeds);

      // Output tensor'Ä± al
      const outputName = this.session!.outputNames[0];
      const outputTensor = results[outputName];
      
      console.log('ğŸ“Š Output tensor boyutu:', outputTensor.dims);
      
      // Float32Array'den normal array'e Ã§evir
      const embedding = Array.from(outputTensor.data as Float32Array);
      
      console.log(`âœ… Embedding Ã§Ä±karÄ±ldÄ±: ${embedding.length} boyutlu`);
      console.log(`ğŸ“ˆ Embedding range: [${Math.min(...embedding).toFixed(3)}, ${Math.max(...embedding).toFixed(3)}]`);
      
      return embedding;
    } catch (error) {
      console.error('âŒ Embedding Ã§Ä±karma hatasÄ±:', error);
      throw error;
    }
  }

  async isModelReady(): Promise<boolean> {
    return this.session !== null;
  }

  async dispose(): Promise<void> {
    if (this.session) {
      await this.session.release();
      this.session = null;
      console.log('ğŸ—‘ï¸ InsightFace Buffalo_L model temizlendi');
    }
  }
}

// Singleton instance
export const insightFaceModel = new InsightFaceBuffaloL();