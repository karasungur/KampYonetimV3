#!/usr/bin/env python3
"""
PKL Face Database Reader and Matcher
GerÃ§ek PKL dosyasÄ±ndan yÃ¼z embeddinglerini okur ve eÅŸleÅŸtirme yapar
"""
import sys
import os
import json
import pickle
import torch
import numpy as np
from typing import Dict, List, Tuple, Any

def load_pkl_database(pkl_path: str) -> Dict[str, Any]:
    """PKL veritabanÄ±nÄ± yÃ¼kle"""
    try:
        # Ã–nce torch.load dene
        try:
            print(f"ğŸ”„ torch.load ile yÃ¼kleniyor: {pkl_path}", file=sys.stderr)
            data = torch.load(pkl_path, map_location='cpu')
            print(f"âœ… torch.load baÅŸarÄ±lÄ±. Tip: {type(data)}", file=sys.stderr)
            return data
        except Exception as torch_error:
            print(f"âš ï¸ torch.load baÅŸarÄ±sÄ±z ({torch_error}), pickle.load ile devam ediliyor...", file=sys.stderr)
            
        # Fallback: pickle.load
        with open(pkl_path, 'rb') as f:
            data = pickle.load(f)
            print(f"âœ… pickle.load ile yÃ¼klendi. Tip: {type(data)}", file=sys.stderr)
            return data
            
    except Exception as e:
        print(f"âŒ PKL yÃ¼kleme hatasÄ±: {e}", file=sys.stderr)
        return None

def extract_embedding_from_face_data(face_data: Any) -> np.ndarray:
    """YÃ¼z verisi dict'inden embedding Ã§Ä±kar"""
    try:
        if isinstance(face_data, dict):
            # InsightFace formatÄ±
            if 'embedding' in face_data:
                embedding = face_data['embedding']
            elif 'normed_embedding' in face_data:
                embedding = face_data['normed_embedding']
            elif 'feat' in face_data:
                embedding = face_data['feat']
            else:
                # Ä°lk numpy array'i bul
                for key, value in face_data.items():
                    if isinstance(value, (np.ndarray, torch.Tensor, list)):
                        if isinstance(value, torch.Tensor):
                            embedding = value.cpu().numpy()
                        elif isinstance(value, list):
                            embedding = np.array(value)
                        else:
                            embedding = value
                        break
                else:
                    print(f"âš ï¸ Embedding bulunamadÄ±, keys: {list(face_data.keys())}", file=sys.stderr)
                    return None
                    
        elif isinstance(face_data, (np.ndarray, torch.Tensor)):
            if isinstance(face_data, torch.Tensor):
                embedding = face_data.cpu().numpy()
            else:
                embedding = face_data
        else:
            print(f"âš ï¸ Bilinmeyen yÃ¼z verisi tipi: {type(face_data)}", file=sys.stderr)
            return None
        
        # NumPy array'e Ã§evir
        if not isinstance(embedding, np.ndarray):
            embedding = np.array(embedding)
            
        # Tek boyutlu yap
        embedding = embedding.flatten()
        
        # L2 normalize et (InsightFace standardÄ±)
        norm = np.linalg.norm(embedding)
        if norm > 0:
            embedding = embedding / norm
            
        print(f"âœ… Embedding Ã§Ä±karÄ±ldÄ±: {embedding.shape} boyut, norm={norm:.3f}", file=sys.stderr)
        return embedding
        
    except Exception as e:
        print(f"âŒ Embedding Ã§Ä±karma hatasÄ±: {e}", file=sys.stderr)
        return None

def cosine_similarity(emb1: np.ndarray, emb2: np.ndarray) -> float:
    """Cosine similarity hesapla (normalize edilmiÅŸ embeddingler iÃ§in dot product)"""
    try:
        if emb1.shape != emb2.shape:
            print(f"âš ï¸ Embedding boyutlarÄ± uyuÅŸmuyor: {emb1.shape} vs {emb2.shape}", file=sys.stderr)
            return 0.0
        
        # Normalize edilmiÅŸ embeddingler iÃ§in dot product = cosine similarity
        similarity = np.dot(emb1, emb2)
        return float(similarity)
        
    except Exception as e:
        print(f"âŒ Similarity hesaplama hatasÄ±: {e}", file=sys.stderr)
        return 0.0

def match_faces(user_embedding: List[float], pkl_path: str, threshold: float = 0.5, model_path: str = None) -> Dict:
    """PKL veritabanÄ±nda yÃ¼z eÅŸleÅŸtirmesi yap"""
    try:
        print(f"ğŸ¦¬ PKL yÃ¼z eÅŸleÅŸtirmesi baÅŸlÄ±yor...", file=sys.stderr)
        print(f"ğŸ“ PKL dosyasÄ±: {pkl_path}", file=sys.stderr)
        print(f"ğŸ¯ Threshold: {threshold}", file=sys.stderr)
        
        # PKL veritabanÄ±nÄ± yÃ¼kle
        pkl_data = load_pkl_database(pkl_path)
        if not pkl_data:
            return {"success": False, "error": "PKL dosyasÄ± yÃ¼klenemedi"}
        
        print(f"ğŸ“Š PKL veritabanÄ± yÃ¼klendi: {len(pkl_data)} kayÄ±t", file=sys.stderr)
        
        # User embedding'i NumPy array'e Ã§evir
        user_emb = np.array(user_embedding)
        if user_emb.ndim > 1:
            user_emb = user_emb.flatten()
        
        # User embedding'i normalize et
        user_norm = np.linalg.norm(user_emb)
        if user_norm > 0:
            user_emb = user_emb / user_norm
            
        print(f"ğŸ‘¤ User embedding: {user_emb.shape} boyut", file=sys.stderr)
        
        # Her PKL kaydÄ± ile karÅŸÄ±laÅŸtÄ±r
        matches = []
        checked_faces = 0
        
        for face_key, face_data in pkl_data.items():
            checked_faces += 1
            
            # Face embedding'i Ã§Ä±kar
            face_embedding = extract_embedding_from_face_data(face_data)
            if face_embedding is None:
                continue
                
            # Similarity hesapla
            similarity = cosine_similarity(user_emb, face_embedding)
            
            if similarity > threshold:
                # Dosya yolunu temizle ve models klasÃ¶rÃ¼ne map et
                image_path = face_key.split('||')[0] if '||' in face_key else face_key
                image_name = os.path.basename(image_path).replace('\\', '/')
                
                # Windows path'inden klasÃ¶r yapÄ±sÄ±nÄ± Ã§Ä±kar
                # D:/Users/.../denemelik\IMG_0909.JPG -> denemelik/IMG_0909.JPG
                windows_parts = image_path.replace('\\', '/').split('/')
                relative_path = image_name  # Default: sadece dosya adÄ±
                
                # denemelik, kiÅŸi_adÄ± gibi klasÃ¶rleri bul
                for i, part in enumerate(windows_parts):
                    if part in ['denemelik'] or (part != '' and not ':' in part and len(part) < 50):
                        # Son 2 parÃ§ayÄ± al (klasÃ¶r/dosya.jpg)
                        if i < len(windows_parts) - 1:
                            relative_path = f"{part}/{windows_parts[-1]}"
                            break
                
                # Model path'i varsa tam yolu oluÅŸtur
                full_model_path = None
                if model_path:
                    potential_paths = [
                        os.path.join(model_path, image_name),
                        os.path.join(model_path, 'denemelik', image_name),
                        os.path.join(model_path, relative_path),
                    ]
                    # Ä°lk bulunan dosyayÄ± kullan
                    for potential_path in potential_paths:
                        if os.path.exists(potential_path):
                            full_model_path = potential_path
                            relative_path = os.path.relpath(potential_path, model_path)
                            break
                
                matches.append({
                    "face_id": face_key,
                    "similarity": similarity,
                    "image_path": image_name,
                    "relative_path": relative_path,
                    "full_path": full_model_path,
                    "original_path": image_path,
                    "metadata": {
                        "type": "pkl_real_match", 
                        "threshold": threshold,
                        "embedding_dim": face_embedding.shape[0],
                        "path_mapped": full_model_path is not None
                    }
                })
        
        # Similarity'ye gÃ¶re sÄ±rala (yÃ¼ksekten dÃ¼ÅŸÃ¼ÄŸe)
        matches.sort(key=lambda x: x["similarity"], reverse=True)
        
        print(f"ğŸ“Š SonuÃ§lar:", file=sys.stderr)
        print(f"- Kontrol edilen yÃ¼z: {checked_faces}", file=sys.stderr) 
        print(f"- Threshold ({threshold}) Ã¼zeri eÅŸleÅŸme: {len(matches)}", file=sys.stderr)
        if matches:
            print(f"- En yÃ¼ksek similarity: {matches[0]['similarity']:.3f}", file=sys.stderr)
            print(f"- En dÃ¼ÅŸÃ¼k similarity: {matches[-1]['similarity']:.3f}", file=sys.stderr)
        
        # Debug: Top 5 similarity
        if checked_faces > 0:
            print(f"ğŸ” Ä°lk 5 yÃ¼z similarity deÄŸerleri:", file=sys.stderr)
            temp_similarities = []
            for face_key, face_data in list(pkl_data.items())[:5]:
                face_embedding = extract_embedding_from_face_data(face_data)
                if face_embedding is not None:
                    similarity = cosine_similarity(user_emb, face_embedding)
                    image_name = os.path.basename(face_key.split('||')[0])
                    temp_similarities.append((image_name, similarity))
            
            temp_similarities.sort(key=lambda x: x[1], reverse=True)
            for i, (name, sim) in enumerate(temp_similarities):
                print(f"  {i+1}. {name}: {sim:.3f}", file=sys.stderr)
        
        return {
            "success": True,
            "matches": matches,
            "total_faces": checked_faces,
            "threshold": threshold,
            "algorithm": "Real PKL InsightFace Matching"
        }
        
    except Exception as e:
        print(f"âŒ PKL eÅŸleÅŸtirme hatasÄ±: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

def main():
    if len(sys.argv) not in [4, 5]:
        print(json.dumps({"success": False, "error": "Usage: python3 pkl_face_matcher.py <pkl_path> <user_embedding_json> <threshold> [model_path]"}))
        sys.exit(1)
    
    pkl_path = sys.argv[1]
    user_embedding_json = sys.argv[2]
    threshold = float(sys.argv[3])
    model_path = sys.argv[4] if len(sys.argv) > 4 else None
    
    if not os.path.exists(pkl_path):
        print(json.dumps({"success": False, "error": f"PKL dosyasÄ± bulunamadÄ±: {pkl_path}"}))
        sys.exit(1)
    
    try:
        # User embedding'i parse et
        user_embedding = json.loads(user_embedding_json)
        
        print(f"ğŸ¦¬ PKL Face Matcher baÅŸlÄ±yor...", file=sys.stderr)
        print(f"ğŸ“ PKL: {pkl_path}", file=sys.stderr) 
        print(f"ğŸ‘¤ User embedding: {len(user_embedding)} boyut", file=sys.stderr)
        print(f"ğŸ¯ Threshold: {threshold}", file=sys.stderr)
        
        # EÅŸleÅŸtirme yap
        result = match_faces(user_embedding, pkl_path, threshold, model_path)
        
        # JSON olarak stdout'a yazdÄ±r
        print(json.dumps(result))
        
    except Exception as e:
        print(json.dumps({"success": False, "error": f"Parsing hatasÄ±: {e}"}))
        sys.exit(1)

if __name__ == "__main__":
    main()